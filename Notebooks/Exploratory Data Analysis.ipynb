{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cae8907",
   "metadata": {},
   "source": [
    "# Predicting Thoracic Pathologies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008be306",
   "metadata": {},
   "source": [
    "## EDA + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac60eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e7831",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a95f56",
   "metadata": {},
   "source": [
    "Our dataset is located at [ChestX-ray8 dataset](https://arxiv.org/abs/1705.02315). The dataset was originally created based on [this publication](https://nihcc.app.box.com/v/ChestXray-NIHCC/file/256057377774). This chest X-ray database (CXR8) was constructed due to addressing a need for hospital-scale radiological imaging presenting realistic clinical and methodological challenges, and present a public database for uses in disease analyses.\n",
    "\n",
    "First, we can take a look at details of our patient data by checking the Data Entry csv file showing general characteristics of each subject's image. Most importantly we will see the finding labels, which are generated via NLP from radiologist reports. We can also see more details including patient age/sex, the view position of the image (i.e. Posterior-Anterior), and the original image's dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = pd.read_csv(\"../Data_Entry_2017_v2020.csv\")\n",
    "patient_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3294326",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data['Finding Labels'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data['Patient ID'].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3741ad",
   "metadata": {},
   "source": [
    "Our patient data totals to 112,120 total medical images for 30,805 unique patients. These images have been collected from patients spanning 1992 - 2015 from the clinical PACS database at NIHCC (National Institutes of Health Clinical Center) in which image labels are mined via NLP from radiology reports. The text-mined disease labels are expectedly >90% accuracy. Images are labeled as XXX_YYY.png, where XXX represents patient ID and YYY represents the CXR ID (or followup) of that patient.\n",
    "\n",
    "Our finding labels include a total of 14 of the most common thoracic pathologies:\n",
    "\n",
    "Atelectasis, Cardiomegaly, Effusion, Infiltration, Mass, Nodule, Penumonia, Penumothorax, Consolidation, Edema, Emphysema, Fibrosis, Pleural Thickening, and Hernia.\n",
    "\n",
    "Using our first patient (57M) as an example, we can see their first CXR (00000001_000.png) which is labeled with cardiomegaly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e79be0",
   "metadata": {},
   "source": [
    "<img src=\"../images/00000001_000.png\" alt=\"U-net Image\" width=\"300\" align=\"middle\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7da4a",
   "metadata": {},
   "source": [
    "## Considerations\n",
    "\n",
    "We want to make sure that our machine learning model(s) recognize specific features and pathologies, rather than simply memorize patient-specific attributes. To ensure this, while splitting our dataset into training, testing, and validation sets we will make sure our all of the images of each patient belong to a single set (i.e. no patient should have one image in a training set and another image in a validation or testing set). \n",
    "\n",
    "This data is already divided accordingly to text files test_list.txt and train_val_list.txt associated with the CXR8 dataset as recommended by the authors. Using a structured split dataset as referenced by [a publication analyzing pruning impact on medical image classifiers](https://arxiv.org/pdf/2308.09180), we have three labeled datasets respecting the patient division structured with one-hot-encoded columns representing pathologies.\n",
    "\n",
    "Each set also contains a column for Subject ID, Image ID, and for No Findings (i.e. none of the 14 pathologies show up). Before we explore the training set in particular to assess data distribution, summaries, and structure we make sure to remove the disease features outside the 14 pathologies being focused on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff19ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient training data\n",
    "# Removing unneeded pathologies from training, validation, and test sets\n",
    "\n",
    "pt_train = pd.read_csv(\"miccai2023_nih-cxr-lt_labels_train.csv\")\n",
    "pt_train = pt_train.drop(columns=['Pneumoperitoneum', \n",
    "                                  'Pneumoperitoneum',\n",
    "                                  'Pneumomediastinum', \n",
    "                                  'Subcutaneous Emphysema',\n",
    "                                  'Tortuous Aorta', \n",
    "                                  'Calcification of the Aorta'],\n",
    "                        axis = 0)\n",
    "pt_valid = pd.read_csv(\"miccai2023_nih-cxr-lt_labels_val.csv\").drop(columns=['Pneumoperitoneum', \n",
    "                                  'Pneumoperitoneum',\n",
    "                                  'Pneumomediastinum', \n",
    "                                  'Subcutaneous Emphysema',\n",
    "                                  'Tortuous Aorta', \n",
    "                                  'Calcification of the Aorta'],\n",
    "                        axis = 0)\n",
    "pt_test = pd.read_csv(\"miccai2023_nih-cxr-lt_labels_test.csv\").drop(columns=['Pneumoperitoneum', \n",
    "                                  'Pneumoperitoneum',\n",
    "                                  'Pneumomediastinum', \n",
    "                                  'Subcutaneous Emphysema',\n",
    "                                  'Tortuous Aorta', \n",
    "                                  'Calcification of the Aorta'],\n",
    "                        axis = 0)\n",
    "\n",
    "pt_train.head()\n",
    "# pt_valid.head()\n",
    "# pt_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18636fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathology_cols = list(pt_train.drop(['id','subj_id'], axis = 1).keys())\n",
    "pathology_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290d62a",
   "metadata": {},
   "source": [
    "We can see that there are no null values in our dataset, and that our data types are standardized (one-hot-encoded as binary int64 values).\n",
    "\n",
    "Now we'll focus on the class distributions for each type of pathology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f06f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count up the number of instances of each class (drop non-class columns from the counts)\n",
    "class_counts = pt_train.sum().drop(['id','subj_id'])\n",
    "\n",
    "for column in class_counts.keys():\n",
    "    print(f\"The class {column} has {pt_train[column].sum()} samples\")\n",
    "\n",
    "# Plotting pathology count distributions\n",
    "sns.barplot(x = class_counts.values, y = class_counts.index, color='r')\n",
    "plt.title('Distribution of Classes for Training Dataset', fontsize=15)\n",
    "plt.xlabel('Number of Patients', fontsize=15)\n",
    "plt.ylabel('Diseases', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75254248",
   "metadata": {},
   "source": [
    "Based on these distributions, it is clear that we have a significantly imbalanced dataset showing a majority of images presenting with no findings. We can also see that hernias are the least represented pathology with only 130 total samples. Turning to literature, we can see that the [following publication](https://arxiv.org/pdf/2208.13365) addresses clinical data imbalances. In particular, it discusses possible avenues to address the distribution imbalance with majority of patients present without any of the 14 indicated pathologies.\n",
    "\n",
    "### Ensuring no patient overlap\n",
    "\n",
    "As mentioned previously, we do not want patient overlap--this way, our model is trained on specific pathological features rather than specific patient features. We can check for overlap between our training, validation and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train_set = set(pt_train.subj_id.values)\n",
    "ids_valid_set = set(pt_valid.subj_id.values)\n",
    "ids_test_set = set(pt_test.subj_id.values)\n",
    "patient_overlap = list(ids_train_set.intersection(ids_valid_set))\n",
    "patient_overlap_test = list(ids_test_set.intersection(ids_valid_set))\n",
    "n_overlap = len(patient_overlap)\n",
    "n_overlap_test = len(patient_overlap_test)\n",
    "print(f'There are {n_overlap} Patient IDs in both the training and validation sets')\n",
    "print(f'There are {n_overlap_test} Patient IDs in both the validation and test sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b7640",
   "metadata": {},
   "source": [
    "## Checking a single CXR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at first image in depth\n",
    "\n",
    "img_dir = '../images'\n",
    "\n",
    "sample_img = pt_train.id[0]\n",
    "raw_image = plt.imread(os.path.join(img_dir, sample_img))\n",
    "plt.imshow(raw_image, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Raw Chest X Ray Image')\n",
    "print(f\"The dimensions of the image are {raw_image.shape[0]} pixels width and {raw_image.shape[1]} pixels height, one single color channel\")\n",
    "print(f\"The maximum pixel value is {raw_image.max():.4f} and the minimum is {raw_image.min():.4f}\")\n",
    "print(f\"The mean value of the pixels is {raw_image.mean():.4f} and the standard deviation is {raw_image.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430eb52",
   "metadata": {},
   "source": [
    "### Image Preprocessing\n",
    "\n",
    "We need to process images for our convolutional neural networks to train more effectively. The images should be normalized and scaled for the CNN to converge faster. Moreover, our limited dataset size (especially for representation on less common pathologies like hernias) can be effectively increased by data augmentation to reduce chances of overfitting. However, we do need to keep in mind that not all augmentation is appropriate--for example, flipping an image (across the Y axis) would place the heart on the wrong side of the patient, which would represent incorrect anatomy for our network to be trained on. \n",
    "\n",
    "Generally speaking, properly preprocessed images should help highlight our essential features while minimizing less relevant ones (ie related to noise, extreme brightness, etc). We start by looking at our first image in greater depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at first image in depth\n",
    "\n",
    "img_dir = '../images'\n",
    "\n",
    "sample_img = pt_train.id[0]\n",
    "raw_image = plt.imread(os.path.join(img_dir, sample_img))\n",
    "plt.imshow(raw_image, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Raw Chest X Ray Image')\n",
    "print(f\"The dimensions of the image are {raw_image.shape[0]} pixels width and {raw_image.shape[1]} pixels height, one single color channel\")\n",
    "print(f\"The maximum pixel value is {raw_image.max():.4f} and the minimum is {raw_image.min():.4f}\")\n",
    "print(f\"The mean value of the pixels is {raw_image.mean():.4f} and the standard deviation is {raw_image.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea5626",
   "metadata": {},
   "source": [
    "Our images are largely 1024 x 1024 in size, but we don't have standardizes mean/StD values for pixel intensity. We can create a list of file paths and multi-hot label vectors, incorporate a tf.data.Dataset using `from_tensor_slices` and map out each image to perform per-image normalization. We can batch and prefetch the dataset for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = pt_train['id'].values\n",
    "labels = pt_train[pathology_cols].values\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_files, labels))\n",
    "# This dataset gives us .png + label pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e86592",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "# DenseNet121 designed for ImageNet images of sisze 224x224, so we reduce size of our original 1024x1024\n",
    "\n",
    "def load_and_preprocess_image(filename, label):\n",
    "    # 1) Construct full path\n",
    "    full_path = tf.strings.join([img_dir, filename], separator=os.path.sep)\n",
    "    \n",
    "    # 2) Load and decode the image\n",
    "    image_bytes = tf.io.read_file(full_path)\n",
    "    image = tf.io.decode_image(image_bytes, channels=3, expand_animations=False)\n",
    "    \n",
    "    # 3) Resize\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    \n",
    "    # 4) Convert to float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # 5) Samplewise normalization => mean=0, std=1\n",
    "    mean, var = tf.nn.moments(image, axes=[0, 1, 2])  # entire image\n",
    "    std = tf.sqrt(var)\n",
    "    image = (image - mean) / tf.maximum(std, 1e-7) # avoid division by 0\n",
    "    \n",
    "    return image, label # returns normalized image + label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a8ff5",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "We'll introduce very small random rotations, zooms, and brightness adjustments to give our smaller dataset a better chance in terms of generalization with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomRotation(0.05), \n",
    "    # No flipping to be safe\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294154be",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "# Smaller input images means bigger batches in GPU memory? \n",
    "# if run out of GPU memory, drop to 16\n",
    "\n",
    "train_dataset = (\n",
    "    dataset\n",
    "    .shuffle(buffer_size=len(pt_train), reshuffle_each_iteration=True) # randomize order of pairs \n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE) # normalizes each image\n",
    "    .map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "       num_parallel_calls=tf.data.AUTOTUNE) # apply augments\n",
    "    .cache() # if enough RAM, allows decoded image to not be repeatedly read from disk each epoch\n",
    "    .batch(BATCH_SIZE) # grouping to 8 images/labels each\n",
    "    .prefetch(tf.data.AUTOTUNE) # more efficient training\n",
    ")\n",
    "\n",
    "# we can iterate through dataset: for batch_images, batch_labels in train_dataset: ...\n",
    "# or with a keras model, train on this dataset directly\n",
    "# or manually fetch batches (below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6df413",
   "metadata": {},
   "source": [
    "Now we can fetch batches and take a look at different images--we can see that our mean and standard deviations for pixels are 0 and 1 respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b443cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch one batch\n",
    "images_batch, labels_batch = next(iter(train_dataset))\n",
    "print(\"Batch of images shape:\", images_batch.shape)  # (8, 224, 224, 1)\n",
    "print(\"Batch of labels shape:\", labels_batch.shape)  # (8, 15)\n",
    "\n",
    "# First image in this batch\n",
    "sample_image = images_batch[0].numpy()  # shape: (320, 320, 1)\n",
    "sample_label = labels_batch[0].numpy()  # shape: (14,)\n",
    "\n",
    "print(f\"Sample image stats: mean={sample_image.mean():.4f}, \"\n",
    "      f\"std={sample_image.std():.4f}\")\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.imshow(sample_image.squeeze(), cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Sample Standardized Chest X-ray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Corresponding label vector:\", sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc948d80",
   "metadata": {},
   "source": [
    "### Data Imbalance Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded7474",
   "metadata": {},
   "source": [
    "As previously discussed, we need to account for data imbalances--particularly due to the fact that a significant majority of CXRs present with no findings. In order to create an effective model or CNN, we need to consider weighted loss functions to address this imbalance. We want to train our model with an evenly balanced dataset so positive and negative training cases are contributing equally to the loss. \n",
    "\n",
    "Using a normal cross-entropy loss function with an unbalanced dataset (like the one we have) results in more prioritization in the majority class (ie negative here) as it contributes more to the loss. \n",
    "\n",
    "One way to change this contribution inequality is multiplying each example from each class by class-specific weight factors so overall contribution of each class is the same.\n",
    "\n",
    "After applying these weightings, we implement a loss function:\n",
    "$$\\mathcal{L}_{cross-entropy}^{w}(x) = - (w_{p} y \\log(f(x)) + w_{n}(1-y) \\log( 1 - f(x) ) ).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f987f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_freqs(labels):\n",
    "    # pos/neg freq for each class given labels\n",
    "    N = labels.shape[0]\n",
    "    positive_frequencies = np.sum(labels, axis = 0) / N\n",
    "    negative_frequencies = 1.0 - positive_frequencies\n",
    "    return positive_frequencies, negative_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pos, freq_neg = compute_class_freqs(labels)\n",
    "print(\"Positive frequencies:\", freq_pos)\n",
    "print(\"Negative frequencies:\", freq_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c81082",
   "metadata": {},
   "source": [
    "We can look at our positive vs negative contribution ratios per each pathology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf33dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(pathology_cols))\n",
    "bar_width = 0.4\n",
    "\n",
    "# Plot pos frequencies\n",
    "plt.bar(\n",
    "    x - bar_width/2,        # Shift the bars to the left by half the bar width\n",
    "    freq_pos,\n",
    "    width=bar_width,\n",
    "    label='Positive',\n",
    ")\n",
    "\n",
    "# Plot neg frequencies\n",
    "plt.bar(\n",
    "    x + bar_width/2,        # Shift the bars to the right by half the bar width\n",
    "    freq_neg,\n",
    "    width=bar_width,\n",
    "    label='Negative',\n",
    ")\n",
    "plt.xticks(x, pathology_cols, rotation=45, ha='right')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Positive vs. Negative Frequencies for Each Pathology')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c812e1",
   "metadata": {},
   "source": [
    "It's clear here that there's a significantly higher contribution by negative cases than positive cases, with the exception of No Finding (representing normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef507c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos\n",
    "pos_contribution = freq_pos * pos_weights \n",
    "neg_contribution = freq_neg * neg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08474e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pos frequencies\n",
    "plt.bar(\n",
    "    x - bar_width/2,        # Shift the bars to the left by half the bar width\n",
    "    pos_contribution,\n",
    "    width=bar_width,\n",
    "    label='Positive',\n",
    ")\n",
    "\n",
    "# Plot neg frequencies\n",
    "plt.bar(\n",
    "    x + bar_width/2,        # Shift the bars to the right by half the bar width\n",
    "    neg_contribution,\n",
    "    width=bar_width,\n",
    "    label='Negative',\n",
    ")\n",
    "plt.xticks(x, pathology_cols, rotation=45, ha='right')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Positive vs. Negative Frequencies for Each Pathology')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b02aed",
   "metadata": {},
   "source": [
    "We create our `get_weighted_loss` function that calculates weighted loss per batch--for multi-class loss, we add up average loss for each individual class. To aavoid possible numerical errors (ie if predicted value is 0), we add a small value $\\epsilon$ to predicted values prior to taking their log values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_loss(pos_weights, neg_weights, episilon = 1e-7):\n",
    "    # return weighted loss function given pos/neg weights (arr for each class, size)\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        # return weighted loss value given tensors of true labels/predicted labels\n",
    "        loss = 0.0\n",
    "        for i in range(len(pos_weights)):\n",
    "            pos_loss = -pos_weights[i] * y_true[:, i] * tf.math.log(y_pred[:, i] + episilon)\n",
    "            neg_loss = -neg_weights[i] * (1.0 - y_true[:, i]) * tf.math.log(1.0 - y_pred[:, i] + episilon)\n",
    "            loss += tf.math.reduce_mean(pos_loss + neg_loss)\n",
    "        return loss\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5e5b5",
   "metadata": {},
   "source": [
    "Now we prepare our validation and test datasets with a `tf.data` pipeline, as we did with our training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_files = pt_valid['id'].values\n",
    "val_labels      = pt_valid[pathology_cols].values\n",
    "val_dataset     = tf.data.Dataset.from_tensor_slices((val_image_files, val_labels))\n",
    "\n",
    "val_dataset = (\n",
    "    val_dataset\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_image_files = pt_test['id'].values\n",
    "test_labels      = pt_test[pathology_cols].values\n",
    "test_dataset     = tf.data.Dataset.from_tensor_slices((test_image_files, test_labels))\n",
    "\n",
    "test_dataset = (\n",
    "    test_dataset\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc933f48",
   "metadata": {},
   "source": [
    "We can start using a pre-trained model loaded directly from Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1adef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "    #freezing layers: fine-tune CXRs and only train last few layers + new head\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# and a logistic layer\n",
    "predictions = Dense(len(pathology_cols), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11fccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR Scheduler so LR adapts when validation loss plateaus\n",
    "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1,          # reduce LR by a factor of 10\n",
    "    patience=2,          # wait 2 epochs of no improvement\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early Stopping when validation doesn't improve\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # or a relevant metric\n",
    "    patience=3,          # how many epochs to wait before stopping\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bfa6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=5\n",
    "    callbacks = [lr_schedule, early_stop]\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    test_data = test_dataset,\n",
    "    epochs = 5,\n",
    "    callbacks = [lr_schedule, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e96fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aef93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cb47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
